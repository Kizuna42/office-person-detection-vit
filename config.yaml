# オフィス人物検出システム設定ファイル
# Office Person Detection System Configuration File

# 動画入力設定
video:
  # 入力動画ファイルのパス
  input_path: "input/merged_moviefiles.mov"

  # タイムラプス動画かどうか
  is_timelapse: true

  # フレーム抽出間隔（分）
  # タイムスタンプベースで5分刻みのフレームを抽出（例: 12:10, 12:15, 12:20）
  frame_interval_minutes: 5

  # タイムスタンプ許容誤差（秒）
  # 目標タイムスタンプから±この秒数以内のフレームを選択
  tolerance_seconds: 60

  # 範囲限定スキャン時のマージン時間（分）
  # start_timeとend_timeが指定されている場合、指定時刻範囲の前後±この分数だけスキャンする
  # デフォルト: 10分
  scan_margin_minutes: 5

  # フレームレート（fps）
  fps: 30

# 人物検出設定
detection:
  # 使用するViTモデル名
  # 選択肢: "facebook/detr-resnet-50", "microsoft/vit-det-base"
  model_name: "facebook/detr-resnet-50"

  # 検出信頼度閾値（0.0-1.0）
  # この値以上の信頼度を持つ検出結果のみを採用
  confidence_threshold: 0.5

  # NMS（Non-Maximum Suppression）閾値（0.0-1.0）
  nms_threshold: 0.4

  # パッチサイズ（ViTの入力パッチサイズ）
  patch_size: 16

  # 使用デバイス
  # 選択肢: "mps" (Apple Silicon GPU), "cuda" (NVIDIA GPU), "cpu"
  device: "mps"

  # バッチサイズ（複数フレームの同時処理数）
  batch_size: 4

# フロアマップ設定
floormap:
  # フロアマップ画像のパス
  image_path: "data/floormap.png"

  # 画像サイズ（ピクセル）
  image_width: 1878
  image_height: 1369

  # 原点オフセット（ピクセル）
  # 画像左上からの原点位置
  image_origin_x: 7
  image_origin_y: 9

  # スケール（mm/pixel）
  image_x_mm_per_pixel: 28.1926406926406
  image_y_mm_per_pixel: 28.241430700447

# ホモグラフィ変換設定
homography:
  # 3x3変換行列
  # カメラ座標からフロアマップ座標（ピクセル）への射影変換
  # 実際の環境に合わせて調整が必要
  matrix:
    - [-0.7522441113290175, -3.2312558061641248, 437.1587328344621]
    - [-1.363838393085345, -3.7773354566090913, 1046.0306165051552]
    - [-0.0010622110702388956, -0.0038281055291385373, 1.0]

# カメラ設定
camera:
  # カメラ位置（フロアマップ上の座標、ピクセル単位）
  position_x: 859
  position_y: 1040

  # カメラ高さ（メートル単位）
  height_m: 2.2

  # カメラ位置をフロアマップ上に表示するか
  show_on_floormap: true

  # カメラアイコンの色（BGR形式）
  marker_color: [0, 0, 255] # 赤色

  # カメラアイコンのサイズ（ピクセル）
  marker_size: 15

# ゾーン定義
# 座標はフロアマップ上のピクセル座標（原点オフセット適用後）
zones:
  # ゾーン1: 左エリア
  - id: "zone_1"
    name: "ゾーン1（左）"
    polygon:
      - [859, 912]
      - [1095, 912]
      - [1095, 1350]
      - [859, 1350]
    priority: 1

  # ゾーン2: 中央エリア
  - id: "zone_2"
    name: "ゾーン2（中央）"
    polygon:
      - [1095, 912]
      - [1331, 912]
      - [1331, 1350]
      - [1095, 1350]
    priority: 2

  # ゾーン3: 右エリア
  - id: "zone_3"
    name: "ゾーン3（右）"
    polygon:
      - [1331, 912]
      - [1567, 912]
      - [1567, 1350]
      - [1331, 1350]
    priority: 3

# 出力設定
output:
  # 出力ディレクトリ
  directory: "output"

  # セッション管理を有効化するか
  # trueの場合、各実行を独立したセッションとして管理
  use_session_management: true

  # 検出結果画像を保存するか
  save_detection_images: true

  # フロアマップ画像を保存するか
  save_floormap_images: true

  # デバッグモード
  # trueの場合、中間処理結果やAttention Mapを出力
  debug_mode: false

  # セッション管理設定
  session:
    # アーカイブ対象の日数（この日数以上古いセッションをアーカイブ）
    archive_days: 30
    # アーカイブ削除対象の日数（この日数以上古いアーカイブを削除）
    delete_archive_days: 90

# タイムスタンプ抽出設定（V2）
timestamp:
  extraction:
    # 信頼度閾値（0.0-1.0）
    # この値未満のOCR結果は除外される
    # タイムラプス動画用に0.5に調整（0.49-0.50の信頼度でも受け入れる）
    confidence_threshold: 0.5

    # リトライ回数
    retry_count: 3

    # 改善機能の有効化
    # TemporalValidatorV2: 適応的許容範囲と異常値リカバリー
    # タイムラプス動画の特性（時間圧縮率約313.4倍）に対応するため有効化
    use_improved_validator: true
    # 重み付けスキーム: エンジン別の重み付けによるコンセンサス（デフォルト: false）
    # 複数エンジン使用時に有効化を推奨
    use_weighted_consensus: false
    # 投票ロジック: 2/3以上のエンジンが一致した結果を採用（デフォルト: false）
    # 複数エンジン使用時に有効化を推奨
    use_voting_consensus: false

    # TemporalValidatorV2の設定
    # タイムラプス動画の特性を考慮（時間圧縮率: 約313.4倍）
    # 5分間隔のフレーム抽出の場合、実際の時間差は300秒（5分）
    validator:
      # ベース許容範囲（秒）
      # タイムラプス動画用: 実際の5分間隔（300秒）+ 許容誤差10秒 = 310秒
      # 適応的許容範囲により動的に調整される
      base_tolerance_seconds: 300.0
      # 履歴サイズ（過去N個のフレーム間隔を保持）
      history_size: 10
      # Z-score閾値（外れ値検出用、大きいほど厳格）
      # タイムラプス動画の変動を考慮して緩和
      z_score_threshold: 3.0

    # ROI設定（画像の右上領域）
    roi:
      x_ratio: 0.70 # 右から35%の位置から
      y_ratio: 0.045 # 上端から
      width_ratio: 0.28 # 幅35%
      height_ratio: 0.06 # 高さ8%

  # フレーム抽出モード
  # "auto_targets": 自動目標タイムスタンプ生成モード
  #   指定範囲のフレームからタイムスタンプを全て抽出し、
  #   5分刻みの目標タイムスタンプを自動生成して各目標に最も近いフレームを選択
  # "manual_targets": 手動目標タイムスタンプ指定モード（デフォルト）
  #   設定ファイルで指定した目標タイムスタンプに最も近いフレームを抽出
  extraction_mode: "auto_targets" # "auto_targets" または "manual_targets"

  # 自動目標タイムスタンプ生成モード用の設定
  auto_targets:
    # 最大処理フレーム数（Noneの場合は全フレームを処理）
    # テスト用に先頭100フレームのみ処理する場合は 100 を指定
    # 本番環境では null に設定して全フレームを処理
    max_frames: 100 # テスト用: 100, 本番用: null
    # タイムスタンプ検証を無効化するか（タイムラプス動画では推奨）
    disable_validation: true

  # サンプリング設定
  # タイムラプス動画の特性を考慮（時間圧縮率: 約313.4倍）
  # 動画の1秒 = 実際の約313秒（約5.2分）
  # 1フレーム = 実際の約10.4秒
  sampling:
    # 粗サンプリング間隔（秒）
    coarse_interval_seconds: 1.0
    # 精密サンプリング間隔（秒）
    # 1秒 → 0.1秒に変更（実際の約31秒間隔、より精密な探索）
    fine_interval_seconds: 0.033
    # 精密サンプリングの探索ウィンドウ（秒）
    search_window_seconds: 0.1

  # 目標タイムスタンプ設定
  target:
    # 開始日時（YYYY-MM-DD HH:MM:SS形式）
    start_datetime: "2025-08-26 16:05:00"
    # 終了日時（YYYY-MM-DD HH:MM:SS形式）
    end_datetime: "2025-08-29 13:45:00"
    # 抽出間隔（分）
    interval_minutes: 5
    # 許容誤差（秒）
    tolerance_seconds: 10

# OCR設定
ocr:
  # 使用するOCRエンジンのリスト
  engines:
    - tesseract
    # - easyocr  # オプション
    # - paddleocr  # オプション
  # Tesseract設定
  tesseract:
    config: "--psm 8 --oem 3" # PSM 8: 単一の単語（最適化テストの結果、PSM 8が最も正確）
    whitelist: "0123456789/:  "

# 精度評価設定
evaluation:
  # Ground Truthデータのパス
  ground_truth_path: "output/labels/result_fixed.json"

  # IoU閾値（True Positiveの判定基準）
  iou_threshold: 0.5

# ファインチューニング設定（オプション）
fine_tuning:
  # ファインチューニングを実行するか
  enabled: false

  # 学習データセットのパス
  dataset_path: "data/office_dataset"

  # エポック数
  epochs: 50

  # 学習率
  learning_rate: 0.0001

  # バッチサイズ
  batch_size: 8

  # Warmupエポック数
  warmup_epochs: 5

  # Layer-wise Learning Rate Decay係数
  layer_decay: 0.65

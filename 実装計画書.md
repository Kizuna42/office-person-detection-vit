# オフィス人流追跡システム - 実装計画書 v1.0

**作成日**: 2025-11-14
**計画期間**: 12週間（約3ヶ月）
**ステータス**: Draft

---

## エグゼクティブサマリー

本計画書は、オフィス内定点カメラ映像から人物検出・追跡・座標変換・ゾーン別集計を行うバッチ処理パイプラインの精度向上と運用体制整備を目的とする。現状では基本的な実装は完了しているが、**実データ上の定量評価が未完了**であり、運用に必要な設定管理・可視化ツール・ReID機能が不足している。

### 主要課題と対応方針

| 課題 | 現状 | 目標 | 対応フェーズ |
|------|------|------|------------|
| 実データ精度の定量化不足 | MOT/再投影誤差が未計測 | MOTA≥0.7, 平均誤差≤2px | Phase 1 (週1-2) |
| パラメータ最適化の体系化 | 経験則ベース | グリッドサーチ+評価 | Phase 2 (週3-5) |
| 可視化UIの分散 | 2つのアプリが並存 | 統合ダッシュボード | Phase 3 (週6-7) |
| 座標変換設定の非標準化 | ドキュメント断片化 | スキーマ+検証ツール | Phase 4 (週8-9) |
| ReID機能の未実装 | 基本embeddingのみ | 類似度計算+閾値設計 | Phase 5 (週10-12) |

### 期待成果

- 実運用データでの **MOTA≥0.7, IDF1≥0.8** の達成
- 再投影誤差 **平均≤2px, 最大≤4px** の達成
- 処理性能 **≤2秒/フレーム, ≤12GBメモリ** の維持
- **運用ダッシュボード**による日常モニタリング体制の確立
- 新規現場セットアップの **工数50%削減**（標準化による）

---

## 1. プロジェクト概要

### 1.1 目的

オフィス内の定点カメラ映像（タイムラプス、約1280×720）から以下の処理を行う：

1. **検出 (Detection)**: ViT/DETRベースの物体検出
2. **追跡 (Tracking)**: DeepSORT系トラッカーによるID付与
3. **座標変換 (Transform)**: カメラ座標→フロアマップ座標（Homography）
4. **ゾーン集計 (Zone)**: ポリゴン内判定による人数カウント
5. **可視化 (Visualization)**: サイドバイサイド動画、フロアマップ、ダッシュボード

### 1.2 技術スタック

- **検出**: `facebook/detr-resnet-50` (Hugging Face)
- **追跡**: DeepSORT (appearance + motion)
- **座標変換**: OpenCV Homography + Camera Calibration
- **可視化**: Streamlit, matplotlib, OpenCV
- **評価**: MOT metrics, 再投影誤差, パフォーマンスプロファイリング

### 1.3 現状の成果物

- メインパイプライン: `main.py` (5フェーズ構成)
- 評価スクリプト: `evaluate_mot_metrics.py`, `evaluate_reprojection_error.py`, `measure_performance.py`
- 可視化ツール: `visualizer_app.py`, `interactive_visualizer.py`, `visual_inspection.py`
- テストカバレッジ: **76%** (目標80%)
- テストデータでの評価: MOTA=1.0, IDF1=1.0 (小規模サンプル)

---

## 2. 現状分析とギャップ

### 2.1 強み (Strengths)

- ✅ エンドツーエンドパイプラインが動作
- ✅ 評価スクリプト群が整備済み
- ✅ テストカバレッジ76% (一定水準)
- ✅ サイドバイサイド動画などの基本可視化が完成

### 2.2 弱み (Weaknesses)

- ❌ **実運用データでの精度評価が未実施**
- ❌ Ground Truthトラックが不足
- ❌ 実対応点データが未取得
- ❌ 可視化UIが2つに分散（保守コスト高）
- ❌ 同一オブジェクト類似度の設計が未成熟

### 2.3 主要ギャップ

| 領域 | ギャップ | 影響度 |
|------|----------|--------|
| 評価 | 実データのMOTA/IDF1が不明 | **Critical** |
| 評価 | 実データの再投影誤差が不明 | **Critical** |
| 最適化 | パラメータチューニングが体系化されていない | High |
| 可視化 | 運用ダッシュボードの機能不足 | High |
| 設定管理 | 座標変換スキーマが非標準 | Medium |
| ReID | 同一オブジェクト類似度が未実装 | Medium |

---

## 3. 実装フェーズ定義

全体を **5つのフェーズ** に分割し、各フェーズで明確な成果物と完了基準を設定する。

### Phase 1: ベースライン確立 (週1-2)

**目的**: 実運用データでの現状精度を定量化
**成果物**: ベースライン評価レポート
**所要時間**: 2週間
**担当**: データサイエンティスト + MLエンジニア

### Phase 2: パラメータ最適化 (週3-5)

**目的**: DeepSORT/座標変換の系統的チューニング
**成果物**: 最適パラメータセット + 比較レポート
**所要時間**: 3週間
**担当**: MLエンジニア + データサイエンティスト

### Phase 3: UI/可視化統合 (週6-7)

**目的**: 運用ダッシュボードの統合と拡張
**成果物**: 統合Streamlitアプリ
**所要時間**: 2週間
**担当**: フロントエンドエンジニア + データサイエンティスト

### Phase 4: 座標変換スキーマ整備 (週8-9)

**目的**: 設定管理の標準化と撮影手順の形式化
**成果物**: 設定スキーマ + 撮影チェックリスト + バリデーションツール
**所要時間**: 2週間
**担当**: MLエンジニア + テクニカルライター

### Phase 5: 同一オブジェクト類似度実装 (週10-12)

**目的**: ReID機能の設計・実装・評価
**成果物**: 類似度計算モジュール + 閾値設計レポート
**所要時間**: 3週間
**担当**: MLエンジニア + データサイエンティスト

---

## 4. 詳細タスクリスト

### Phase 1: ベースライン確立 (週1-2)

#### T1.1: 実データ収集と準備
- **担当**: データエンジニア
- **所要時間**: 3日
- **依存**: なし
- **説明**:
  - 代表的な実セッション動画を3-5本選定（昼/夜、混雑/非混雑）
  - 各セッションの基本情報をメタデータ化
- **成果物**:
  - `input/sessions/session_<id>/video.mov`
  - `input/sessions/session_<id>/metadata.json`
- **完了基準**:
  - 異なる条件のセッションが最低3本
  - メタデータに撮影日時、照明条件、想定人数を記載

#### T1.2: Ground Truthトラック作成
- **担当**: アノテーター + データサイエンティスト
- **所要時間**: 5日
- **依存**: T1.1
- **説明**:
  - 1セッション（5-10分）についてフレーム単位でID付きバウンディングボックスをアノテート
  - アノテーションツール（CVAT, Labelbox等）を使用
- **成果物**:
  - `data/ground_truth/session_<id>_gt_tracks.json`
- **完了基準**:
  - 最低300フレーム分のGTを作成
  - フォーマットがMOT評価スクリプトと互換

#### T1.3: 実対応点データ取得
- **担当**: 現場担当者 + MLエンジニア
- **所要時間**: 2日
- **依存**: なし
- **説明**:
  - 床面上にマーカー（10-20点）を配置
  - カメラ画像上の座標とフロアマップ上の座標を記録
- **成果物**:
  - `data/correspondence_points_cam<id>.json`
- **完了基準**:
  - カメラごとに最低10点
  - 視野全体に分散配置

#### T1.4: ベースライン実行
- **担当**: MLエンジニア
- **所要時間**: 1日
- **依存**: T1.1
- **説明**:
  - 現行configで全セッションに対してパイプライン実行
  ```bash
  python main.py --config config.yaml --session-tag baseline-20251114
  ```
- **成果物**:
  - `output/sessions/baseline-20251114/`配下に全phase出力
- **完了基準**:
  - エラーなく完了
  - tracking結果がJSON形式で保存

#### T1.5: MOTメトリクス計測
- **担当**: データサイエンティスト
- **所要時間**: 1日
- **依存**: T1.2, T1.4
- **説明**:
  ```bash
  python scripts/evaluate_mot_metrics.py \
    --gt data/ground_truth/session_<id>_gt_tracks.json \
    --tracks output/sessions/baseline-20251114/phase2.5_tracking/tracks.json \
    --frames <N> \
    --output output/sessions/baseline-20251114/mot_metrics.json
  ```
- **成果物**:
  - `mot_metrics.json` (MOTA, IDF1, ID switches等)
- **完了基準**:
  - 全セッションでMOTA/IDF1が算出
  - 目標値（MOTA≥0.7, IDF1≥0.8）との差を定量化

#### T1.6: 再投影誤差計測
- **担当**: MLエンジニア
- **所要時間**: 1日
- **依存**: T1.3
- **説明**:
  ```bash
  python scripts/evaluate_reprojection_error.py \
    --points data/correspondence_points_cam01.json \
    --config config.yaml \
    --output output/baseline_reprojection_error.json \
    --error-map output/baseline_error_map.png
  ```
- **成果物**:
  - `baseline_reprojection_error.json` (平均/最大誤差)
  - `baseline_error_map.png` (誤差ヒートマップ)
- **完了基準**:
  - 平均誤差≤2px、最大誤差≤4pxの達成度を確認

#### T1.7: パフォーマンス計測
- **担当**: MLエンジニア
- **所要時間**: 0.5日
- **依存**: T1.4
- **説明**:
  ```bash
  python scripts/measure_performance.py \
    --video input/sessions/session_<id>/video.mov \
    --config config.yaml \
    --output output/baseline_performance.json
  ```
- **成果物**:
  - `baseline_performance.json` (処理時間、メモリ使用量)
- **完了基準**:
  - 1フレーム平均処理時間、95%ile、最大値を記録
  - 目標≤2秒/フレーム、≤12GBとの比較

#### T1.8: ベースライン評価レポート作成
- **担当**: データサイエンティスト
- **所要時間**: 1日
- **依存**: T1.5, T1.6, T1.7
- **説明**:
  - 全メトリクスを統合したレポートを作成
  - 目標値との差異分析
  - 改善の優先順位付け
- **成果物**:
  - `docs/baseline_evaluation_report_20251114.md`
- **完了基準**:
  - エグゼクティブサマリー、詳細メトリクス、推奨事項を含む
  - ステークホルダーレビュー完了

---

### Phase 2: パラメータ最適化 (週3-5)

#### T2.1: 実験設計
- **担当**: データサイエンティスト
- **所要時間**: 2日
- **依存**: T1.8
- **説明**:
  - チューニング対象パラメータの選定
    - appearance_weight: [0.5, 0.65, 0.8]
    - motion_weight: 1 - appearance_weight
    - iou_threshold: [0.3, 0.35, 0.4]
    - max_age: [30, 50, 70]
    - use_distortion_correction: [true, false]
  - グリッドサーチ vs ベイズ最適化の選択
- **成果物**:
  - `experiments/tuning_plan.md`
  - パラメータグリッド定義JSON
- **完了基準**:
  - 実験数が10-20通りに収まる
  - 評価基準（MOTA, IDF1, 処理時間）の重み付けを定義

#### T2.2: Config生成スクリプト作成
- **担当**: MLエンジニア
- **所要時間**: 1日
- **依存**: T2.1
- **説明**:
  - パラメータグリッドから複数のconfig.yamlを自動生成
  ```bash
  python scripts/generate_configs.py \
    --base-config config.yaml \
    --param-grid experiments/param_grid.json \
    --output-dir experiments/configs/
  ```
- **成果物**:
  - `scripts/generate_configs.py`
  - `experiments/configs/config_<k>.yaml` (k=1..N)
- **完了基準**:
  - 全configファイルがバリデーション通過

#### T2.3: 実験実行自動化
- **担当**: MLエンジニア
- **所要時間**: 2日
- **依存**: T2.2
- **説明**:
  - 各configでパイプラインを実行し、メトリクスを集約
  ```bash
  python scripts/run_experiments.py \
    --config-dir experiments/configs/ \
    --video-dir input/sessions/ \
    --output-dir experiments/results/
  ```
- **成果物**:
  - `scripts/run_experiments.py`
  - `experiments/results/<config_id>/summary.json`
- **完了基準**:
  - 全実験がエラーなく完了
  - 各summaryにMOTA, IDF1, 処理時間が記録

#### T2.4: 結果分析と可視化
- **担当**: データサイエンティスト
- **所要時間**: 3日
- **依存**: T2.3
- **説明**:
  - パラメータごとのメトリクス比較表作成
  - MOTA vs 処理時間のPareto最適曲線
  - 統計的有意差検定（ペアt検定等）
- **成果物**:
  - `experiments/analysis_report.md`
  - 比較可視化グラフ（PNG/PDF）
- **完了基準**:
  - ベースライン比で改善したパラメータセットを特定
  - トレードオフ分析（精度 vs 速度）を提示

#### T2.5: 最適パラメータの選定と適用
- **担当**: データサイエンティスト + プロダクトオーナー
- **所要時間**: 1日
- **依存**: T2.4
- **説明**:
  - 運用要件（精度、速度、コスト）を考慮して1-2パターンを推奨
  - `config.yaml`を更新
- **成果物**:
  - `config.yaml` (更新版)
  - `docs/recommended_params.md`
- **完了基準**:
  - ステークホルダー承認
  - 推奨設定でMOTA≥0.7, IDF1≥0.8を達成

#### T2.6: 回帰テスト
- **担当**: MLエンジニア
- **所要時間**: 1日
- **依存**: T2.5
- **説明**:
  - 新パラメータで全テストセッションを再実行
  - ベースラインとの比較
- **成果物**:
  - `experiments/regression_test_report.md`
- **完了基準**:
  - 精度向上が全セッションで再現
  - 処理時間が目標内

---

### Phase 3: UI/可視化統合 (週6-7)

#### T3.1: UI統合設計
- **担当**: フロントエンドエンジニア + UXデザイナー
- **所要時間**: 2日
- **依存**: なし
- **説明**:
  - `visualizer_app.py`と`interactive_visualizer.py`の機能を統合
  - 運用ダッシュボードの画面設計
    - フレーム単位ビュー
    - セッション集約ビュー
    - セッション比較ビュー
- **成果物**:
  - `docs/ui_integration_design.md`
  - ワイヤーフレーム（Figma等）
- **完了基準**:
  - 必要な機能リストが明確
  - ステークホルダー承認

#### T3.2: コードリファクタリング
- **担当**: フロントエンドエンジニア
- **所要時間**: 3日
- **依存**: T3.1
- **説明**:
  - `interactive_visualizer.py`をベースに機能統合
  - `visualizer_app.py`をdeprecate
  - モジュール化（セッション読み込み、プロット生成、UI要素）
- **成果物**:
  - `tools/dashboard.py` (統合版)
  - `tools/visualizer_app.py` → deprecation notice追加
- **完了基準**:
  - 既存の全機能が動作
  - コードカバレッジ維持

#### T3.3: セッション集約ビューの実装
- **担当**: フロントエンドエンジニア
- **所要時間**: 2日
- **依存**: T3.2
- **説明**:
  - セッション単位の統計情報表示
    - 総滞在人数
    - ゾーン別平均人数
    - 最大同時在室人数
    - 推定IDスイッチ数
- **成果物**:
  - `tools/dashboard.py`内の集約ビュー機能
- **完了基準**:
  - summary.jsonから自動読み込み
  - グラフ表示が正常動作

#### T3.4: セッション比較ビューの実装
- **担当**: フロントエンドエンジニア
- **所要時間**: 2日
- **依存**: T3.2
- **説明**:
  - 複数セッションのメトリクス比較
  - パラメータセット別の色分け表示
  - MOTA/IDF1/処理時間の並行座標プロット
- **成果物**:
  - `tools/dashboard.py`内の比較ビュー機能
- **完了基準**:
  - 2つ以上のセッションを選択して比較可能
  - パラメータの違いが視覚的に明確

#### T3.5: 評価スクリプト統合
- **担当**: フロントエンドエンジニア
- **所要時間**: 1日
- **依存**: T3.2
- **説明**:
  - UIから評価スクリプトを起動するボタン追加
  ```python
  if st.button("Run MOT Evaluation"):
      subprocess.run([...])
  ```
  - 結果JSONをインライン表示
- **成果物**:
  - `tools/dashboard.py`内のスクリプト実行機能
- **完了基準**:
  - 各評価スクリプトが正常実行
  - 結果が即座にUI反映

#### T3.6: UI テストとドキュメント
- **担当**: QAエンジニア + テクニカルライター
- **所要時間**: 1日
- **依存**: T3.3, T3.4, T3.5
- **説明**:
  - 手動テスト（全機能の動作確認）
  - 操作マニュアルの作成
- **成果物**:
  - `docs/dashboard_user_guide.md`
  - テストレポート
- **完了基準**:
  - 全機能が正常動作
  - マニュアルに従って初見ユーザーが操作可能

---

### Phase 4: 座標変換スキーマ整備 (週8-9)

#### T4.1: 設定スキーマの定義
- **担当**: MLエンジニア
- **所要時間**: 2日
- **依存**: なし
- **説明**:
  - YAMLテンプレートを`config/calibration_template.yaml`として追加
  - 必須フィールド、型、デフォルト値を定義
  - ドキュメントに各パラメータの意味を記載
- **成果物**:
  - `config/calibration_template.yaml`
  - `config/calibration_schema.md`
- **完了基準**:
  - 全必須フィールドが明記
  - サンプル値が動作可能

#### T4.2: ConfigManagerのバリデーション強化
- **担当**: MLエンジニア
- **所要時間**: 2日
- **依存**: T4.1
- **説明**:
  - `ConfigManager`に必須キーチェック機能追加
  - 型検証（pydantic or jsonschema）
  - 起動時のvalidation失敗でfail-fast
- **成果物**:
  - `src/config/config_manager.py` (更新)
  - ユニットテスト追加
- **完了基準**:
  - 必須キー欠落時にエラーメッセージ表示
  - 型不一致時にエラーメッセージ表示
  - テストカバレッジ90%以上

#### T4.3: 撮影手順チェックリスト作成
- **担当**: テクニカルライター + 現場担当者
- **所要時間**: 2日
- **依存**: T4.1
- **説明**:
  - カメラ設置時に収集すべき情報を列挙
    - フロアマップ画像
    - カメラID、設置位置
    - マーカー配置（床面上10-20点）
    - camera pixel座標 ↔ floormap pixel座標
    - カメラ解像度
  - チェックリスト形式で整理
- **成果物**:
  - `docs/camera_setup_checklist.md`
- **完了基準**:
  - 初見の現場担当者が手順に従える
  - 設定ファイルの各フィールドと1:1対応

#### T4.4: キャリブレーションウィザードの拡張
- **担当**: MLエンジニア
- **所要時間**: 3日
- **依存**: T4.2
- **説明**:
  - `tools/homography_calibrator.py`を対話的に改良
  ```bash
  python tools/homography_calibrator.py --interactive
  ```
  - マーカークリック → config生成まで一貫
- **成果物**:
  - `tools/homography_calibrator.py` (更新)
- **完了基準**:
  - コマンド1つでキャリブレーション完了
  - 生成されたconfigがvalidation通過

#### T4.5: メタデータスナップショット機能
- **担当**: MLエンジニア
- **所要時間**: 1日
- **依存**: T4.2
- **説明**:
  - `main.py`実行時に使用したconfigを`metadata.json`に保存
  - homography, distortion, scaleなど全パラメータを記録
- **成果物**:
  - `main.py`更新
  - `output/sessions/<session_tag>/metadata.json`
- **完了基準**:
  - 各セッションで再現可能な設定が保存

---

### Phase 5: 同一オブジェクト類似度実装 (週10-12)

#### T5.1: ラベル付きペアデータ作成
- **担当**: アノテーター + データサイエンティスト
- **所要時間**: 4日
- **依存**: なし
- **説明**:
  - trackletペア（同一人物/別人物）を100-200ペア作成
  - 既存トラックJSONから候補を抽出
  - 手動でラベル付け
- **成果物**:
  - `data/reid_labels/tracklet_pairs.json`
- **完了基準**:
  - 最低100ペア
  - 同一:別人 = 1:1程度のバランス

#### T5.2: 類似度計算モジュール設計
- **担当**: MLエンジニア
- **所要時間**: 2日
- **依存**: なし
- **説明**:
  - 外観類似度: cosine similarity（DeepSORT embedding）
  - 動作類似度: 速度ベクトル、方向ヒストグラム、位置分布
  - 総合スコア: S = w_app * S_app - w_motion * D_motion
- **成果物**:
  - `src/reid/similarity_calculator.py`
  - 設計ドキュメント
- **完了基準**:
  - interface定義
  - ユニットテスト（モックデータ）

#### T5.3: 類似度計算の実装
- **担当**: MLエンジニア
- **所要時間**: 3日
- **依存**: T5.2
- **説明**:
  - 各trackletについて平均/中央値embeddingを計算
  - motion featureの抽出（numpy/scipy）
  - 総合スコアの計算
- **成果物**:
  - `src/reid/similarity_calculator.py` (実装)
- **完了基準**:
  - 全機能がユニットテスト通過
  - ペアデータで動作確認

#### T5.4: 閾値決定と評価
- **担当**: データサイエンティスト
- **所要時間**: 3日
- **依存**: T5.1, T5.3
- **説明**:
  - ラベル付きペアに対してROC/PR曲線を算出
  - F1最大点 or TPR=0.95点を閾値として採用
  - precision/recall/F1を算出
- **成果物**:
  - `experiments/reid_evaluation.ipynb`
  - `docs/reid_threshold_report.md`
- **完了基準**:
  - 閾値が定量的根拠で決定（例: S≥0.8）
  - F1≥0.9（小規模データ目標）

#### T5.5: MOT評価への統合
- **担当**: MLエンジニア
- **所要時間**: 2日
- **依存**: T5.3
- **説明**:
  - `evaluate_mot_metrics.py`にfalse-merge/false-split測定を追加
  - 類似度スコアに基づく再結合ロジックの実験
- **成果物**:
  - `scripts/evaluate_mot_metrics.py` (更新)
- **完了基準**:
  - false-merge/false-split数が定量化
  - 再結合ロジックがMOTA/IDF1を改善

#### T5.6: ドキュメントとベストプラクティス
- **担当**: データサイエンティスト + テクニカルライター
- **所要時間**: 1日
- **依存**: T5.4, T5.5
- **説明**:
  - ReID機能の使い方をドキュメント化
  - 閾値調整のガイドライン
  - マルチカメラ対応の将来計画
- **成果物**:
  - `docs/reid_user_guide.md`
  - `docs/reid_future_work.md`
- **完了基準**:
  - エンジニアが独自に閾値調整可能

---

## 5. リソース計画

### 5.1 人員配置

| 役割 | 担当者数 | 主要フェーズ | 所要工数（人週） |
|------|----------|-------------|------------------|
| データサイエンティスト | 1名 | Phase 1, 2, 5 | 8週 |
| MLエンジニア | 1-2名 | Phase 1, 2, 4, 5 | 10週 |
| フロントエンドエンジニア | 1名 | Phase 3 | 2週 |
| データエンジニア | 1名 | Phase 1 | 0.5週 |
| アノテーター | 1-2名 | Phase 1, 5 | 2週 |
| QAエンジニア | 1名 | Phase 3 | 0.5週 |
| テクニカルライター | 1名 | Phase 3, 4, 5 | 1週 |
| プロダクトオーナー | 1名 | Phase 2 | 0.2週 |

### 5.2 インフラ要件

- **計算リソース**
  - GPU: NVIDIA V100/A100 × 1-2台（学習・推論用）
  - CPU: 16コア以上
  - メモリ: 32GB以上
  - ストレージ: 500GB以上（動画・出力保存用）

- **ソフトウェア**
  - Python 3.8+
  - PyTorch/TensorFlow
  - OpenCV
  - Streamlit
  - MLflow/WandB（オプション）

### 5.3 コスト概算

| 項目 | 単価 | 数量 | 合計 |
|------|------|------|------|
| 人件費（エンジニア） | ¥500,000/人月 | 5人月 | ¥2,500,000 |
| アノテーション外注 | ¥1,000/時間 | 80時間 | ¥80,000 |
| クラウドGPU（A100） | ¥200/時間 | 200時間 | ¥40,000 |
| ソフトウェアライセンス | - | - | ¥50,000 |
| **合計** | | | **¥2,670,000** |

---

## 6. リスク管理

### 6.1 主要リスク

| リスク | 影響度 | 発生確率 | 緩和策 |
|--------|--------|----------|--------|
| Ground Truthデータの品質不足 | High | Medium | - アノテーションガイドライン整備<br>- 複数人でクロスチェック<br>- 不確実なフレームはスキップ |
| 実データでのMOTA目標未達 | Critical | Medium | - 早期に問題検出（Phase 1）<br>- Phase 2で段階的改善<br>- 必要に応じて検出モデル再学習 |
| 処理時間の超過 | High | Low | - Phase 1でパフォーマンス計測<br>- ボトルネック特定と最適化<br>- フレーム間引きなどの代替策 |
| マルチカメラ対応の複雑性 | Medium | Medium | - Phase 5はシングルカメラで完結<br>- マルチカメラは将来フェーズに分離 |
| リソース不足 | Medium | Low | - クラウドGPUの利用<br>- タスクの優先順位付け<br>- スコープ調整 |

### 6.2 リスク対応計画

- **週次リスクレビュー**: 毎週金曜日にリスク状況を確認
- **Go/No-Go判断ポイント**:
  - Phase 1終了時: ベースライン精度が極端に低い場合は計画見直し
  - Phase 2終了時: パラメータ最適化で改善なしの場合はモデル変更検討
- **エスカレーションパス**: 重大リスクはプロダクトオーナー → 経営層

---

## 7. 成功基準とマイルストーン

### 7.1 Phase別完了基準

| Phase | 完了基準 | マイルストーン日 |
|-------|----------|------------------|
| Phase 1 | - 実データでMOTA/IDF1/再投影誤差を計測<br>- ベースライン評価レポート完成 | Week 2終了時 |
| Phase 2 | - MOTA≥0.7, IDF1≥0.8達成<br>- 推奨パラメータセット決定 | Week 5終了時 |
| Phase 3 | - 統合ダッシュボード稼働<br>- 全機能が正常動作 | Week 7終了時 |
| Phase 4 | - 設定スキーマ＋撮影チェックリスト完成<br>- 新規現場でconfigエラー0 | Week 9終了時 |
| Phase 5 | - ReID類似度計算実装<br>- 閾値決定（F1≥0.9目標） | Week 12終了時 |

### 7.2 最終成功基準

- ✅ **精度**: MOTA≥0.7, IDF1≥0.8（実運用データ）
- ✅ **座標変換**: 平均誤差≤2px, 最大誤差≤4px
- ✅ **パフォーマンス**: ≤2秒/フレーム, ≤12GBメモリ
- ✅ **カバレッジ**: ≥80%
- ✅ **運用効率**: 新規現場セットアップ工数50%削減

### 7.3 マイルストーンチャート

```
Week 1-2:  [==========] Phase 1: ベースライン確立
Week 3-5:  [================] Phase 2: パラメータ最適化
Week 6-7:  [==========] Phase 3: UI統合
Week 8-9:  [==========] Phase 4: スキーマ整備
Week 10-12: [===============] Phase 5: ReID実装
Week 13:   [====] 統合テスト＆最終レポート
```

---

## 8. 継続的改善計画

### 8.1 短期（3ヶ月後）

- 実運用データの蓄積と定期評価
- MOT/再投影誤差の月次モニタリング
- パフォーマンスの継続監視

### 8.2 中期（6ヶ月後）

- マルチカメラ対応の実装
- ReIDモデルの専用fine-tuning
- 運用ダッシュボードへのアラート機能追加

### 8.3 長期（1年後）

- 大規模ReIDデータセットでの再学習
- ByteTrack/OC-SORT等の最新tracker導入検証
- Grafana/Prometheus連携によるリアルタイム監視

---

## 9. 付録

### 9.1 評価指標の数式

#### MOTA (Multiple Object Tracking Accuracy)
$$
\text{MOTA} = 1 - \frac{\sum_t (\text{FN}_t + \text{FP}_t + \text{IDSW}_t)}{\sum_t \text{GT}_t}
$$

#### IDF1 (Identity F1-score)
$$
\text{IDF1} = \frac{2 \cdot \text{IDTP}}{2 \cdot \text{IDTP} + \text{IDFP} + \text{IDFN}}
$$

#### 再投影誤差
$$
e_i = \left\| p^{\text{proj}}_i - p^{\text{gt}}_i \right\|_2
$$
$$
\bar{e} = \frac{1}{N}\sum_i e_i, \quad e_{\max} = \max_i e_i
$$

### 9.2 参考資料

- MOT Challenge公式: https://motchallenge.net/
- DeepSORT論文: https://arxiv.org/abs/1703.07402
- OpenCV Homography: https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html

### 9.3 変更履歴

| 版 | 日付 | 変更内容 | 承認者 |
|----|------|----------|--------|
| 1.0 | 2025-11-14 | 初版作成 | - |

---

**承認**

| 役割 | 氏名 | 署名 | 日付 |
|------|------|------|------|
| プロジェクトマネージャー | | | |
| プロダクトオーナー | | | |
| 技術リード | | | |

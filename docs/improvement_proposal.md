# MLOps / CV パイプライン改善提案書

## 1. 現状分析と誤差要因の特定

### 1.1 Main パイプラインの構造的理解
現在のパイプラインは、2D-to-2D のホモグラフィ変換（`CoordinateTransformer`）に強く依存しています。この変換行列 `H` は、`tools/homography_calibrator.py` を用いて手動で対応点をクリックすることで算出されています。

**現状のデータフロー:**
1.  **Phase 1 (Frame Extraction)**: タイムスタンプ抽出精度は `TemporalValidatorV2` で担保されているが、フレーム選択のズレは移動体の位置ズレに直結する。
2.  **Phase 2 (Detection)**: DETR の BBox 下端中心を「足元」と仮定。
    *   *誤差要因*: 人物の姿勢、遮蔽、BBox のゆらぎにより、「足元」の定義が曖昧になりやすい。
3.  **Phase 3 (Coordinate Transformation)**: `homography.matrix` (3x3) を使用。
    *   *誤差要因*: 手動クリックによる対応点の誤差（特に遠方で増幅）。
    *   *誤差要因*: **物理的カメラパラメータ（高さ、角度）の欠如**。現在の `H` は純粋な数学的フィッティングであり、カメラの物理的な設置状況（高さ 2.2m、俯角など）との整合性が保証されていない。
4.  **Phase 4/5 (Aggregation/Vis)**: 変換後の座標に依存。

### 1.2 座標変換精度の根本的問題
現状の最大の問題は、**「物理パラメータ（Extrinsics/Intrinsics）と変換行列（Homography）の乖離」**です。

*   **現状**: `config.yaml` に `camera.height_m` や `position_x/y` があるが、これらは可視化（アイコン表示）にしか使われておらず、座標変換計算には一切寄与していない。
*   **結果**: カメラがわずかに傾いた場合、物理的には「Pitch が 1度変わった」だけだが、ホモグラフィ行列の全要素が複雑に変化するため、手動での微修正が極めて困難。

---

## 2. 座標変換精度改善戦略

### 2.1 カメラパラメータベースのホモグラフィ生成 (Camera Projection Model)
ホモグラフィ行列を「点の対応」から直接求めるのではなく、**カメラの物理パラメータから計算で導出する**方式へ移行（または併用）することを提案します。

**導入すべきパラメータ:**
*   **Extrinsics (外部パラメータ)**:
    *   `camera_height` (m): 床面からの高さ
    *   `pitch` (deg): 俯角（下向きの角度）
    *   `yaw` (deg): 方位角（左右の首振り）
    *   `roll` (deg): 回転角（水平の傾き）
*   **Intrinsics (内部パラメータ)**:
    *   `focal_length` (px): 焦点距離（画角に関与）
    *   `principal_point` (px): 画像中心

**数理的アプローチ:**
物理パラメータから Rotation Matrix ($R$) と Translation Vector ($t$) を構成し、平面ホモグラフィ $H$ を解析的に導出します。
$$ H = K \cdot [r_1, r_2, t] $$
ここで $K$ は内部パラメータ行列、$r_1, r_2$ は回転行列の列ベクトル、$t$ は並進ベクトルです。

### 2.2 Human-in-the-loop 調整ツールの開発
数値（行列の各要素）を直接いじるのではなく、人間が直感的に理解できる「角度」「高さ」をスライダーで操作し、その結果（グリッド線の投影）をリアルタイムに確認できるツールを導入します。

**機能要件:**
1.  **入力**: 現在のフレーム画像 + フロアマップ
2.  **操作**: Pitch, Yaw, Roll, Height, FOV のスライダー調整
3.  **可視化**:
    *   フロアマップのグリッド線をカメラ画像上に投影 (Reprojection)
    *   カメラ画像の視錐台 (Frustum) をフロアマップ上に投影
4.  **出力**: 調整後のパラメータから計算された `homography.matrix` を `config.yaml` に書き出し

---

## 3. PDCA ワークフロー設計

### 3.1 改善サイクル (Iterative Refinement)

1.  **Plan (仮説設定)**
    *   初期パラメータの設定（例: 高さ2.2m, 俯角30度と仮定）。
    *   `side_by_side_tracking.mp4` を確認し、ズレの傾向を把握（例：「画面奥に行くと座標が手前にずれる」→ Pitch または Height の調整が必要）。

2.  **Do (パラメータ調整)**
    *   新設する **Interactive Camera Adjuster** を起動。
    *   スライダーを操作し、グリッド線が床面のタイルや構造物と平行になるように調整。
    *   特に「消失点（平行線が交わる点）」の位置を合わせることで、Yaw/Pitch を高精度に決定可能。

3.  **Check (検証)**
    *   調整後のパラメータでパイプラインを再実行（または検証用スクリプト実行）。
    *   `side_by_side_tracking.mp4` で、人物の足元と検出ポイントの整合性を確認。
    *   **定量評価**: 既知のランドマーク（柱、ドア位置など）の座標誤差を計測。

4.  **Act (定着・改善)**
    *   最適なパラメータを `config.yaml` に保存。
    *   系統的な誤差（レンズ歪みなど）が残る場合は、歪み補正係数 ($k_1, k_2$) の導入を検討。

---

## 4. 実装計画 (Action Plan)

### Step 1: パラメータ管理構造の更新
`config.yaml` に計算用カメラパラメータセクションを追加。

```yaml
camera_params:
  height_m: 2.2
  pitch_deg: 45.0
  yaw_deg: 0.0
  roll_deg: 0.0
  focal_length_x: 1000.0  # 推定値から開始
  center_x: 640.0
  center_y: 360.0
```

### Step 2: ホモグラフィ生成ロジックの実装
物理パラメータから $H$ を生成する関数 `compute_homography_from_params` を実装。

### Step 3: Interactive Adjuster の作成
OpenCV GUI を用いた軽量な調整ツール `tools/adjust_camera_params.py` を実装。

### Step 4: 検証とマニュアル化
調整手順書を作成し、オペレーターが `side_by_side` 動画を見ながら微調整できるフローを確立。

---

## 必要インプットチェックリスト

| 項目 | 現状 | 必要アクション |
| :--- | :--- | :--- |
| **カメラ設置高さ** | `config.yaml` に 2.2m と記載 | 実測値か確認が必要。不明な場合は調整の起点とする。 |
| **レンズ仕様** | 不明 | 焦点距離の初期推定に必要。広角か標準かだけでも判明すると有利。 |
| **基準点（ランドマーク）** | フロアマップ上の柱等の位置 | 精度評価のために、マップ上の特定地点の座標値が必要。 |
